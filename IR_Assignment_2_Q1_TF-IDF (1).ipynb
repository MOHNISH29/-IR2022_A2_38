{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3938fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import math\n",
    "import statistics\n",
    "from statistics import mode\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5373d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "data = []\n",
    "for filename in os.listdir(\"data_folder\"):\n",
    "    file_names.append(filename)\n",
    "    \n",
    "    try:\n",
    "            f = open(\"data_folder/\"+filename , encoding='utf8')\n",
    "            var=f.read().replace('\\n',\" \")\n",
    "            data.append(var)\n",
    "            \n",
    "    except Exception as e:\n",
    "            f = open(\"data_folder/\"+filename , encoding='unicode_escape')\n",
    "            var=f.read().replace('\\n',\" \")\n",
    "            data.append(var)\n",
    "            \n",
    "    f.close();\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05ff1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(d):\n",
    "    no_punc = []\n",
    "    d_lower=d.lower()\n",
    "    \n",
    "    nltk_tokens = nltk.word_tokenize(d_lower)\n",
    "    \n",
    "    stop_words_removed = []\n",
    "    for w in nltk_tokens:\n",
    "        if w not in stop_words:\n",
    "            stop_words_removed.append(w)\n",
    "    \n",
    "    \n",
    "    new_words = []\n",
    "    for x in stop_words_removed:\n",
    "        if(x.isalnum() and x!=\" \"):\n",
    "            new_words.append(x)\n",
    "        \n",
    "        \n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2baa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count=0\n",
    "preprocessed_data = []\n",
    "for d in data:\n",
    "    data_new = preprocessing(d)\n",
    "    word_count = word_count  +len(data_new)\n",
    "    preprocessed_data.append(data_new)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7dfd997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071853\n"
     ]
    }
   ],
   "source": [
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165fe416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67128\n"
     ]
    }
   ],
   "source": [
    "vocab_list = []\n",
    "count = 0\n",
    "for p in preprocessed_data :\n",
    "    i=0\n",
    "    for i in range(len(p)):\n",
    "        if not p[i] in vocab_list:\n",
    "            count=count+1\n",
    "            vocab_list.append(p[i])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2373ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Vocabulary_list' , 'wb') as f:\n",
    "           pickle.dump(vocab_list , f)\n",
    "with open('Vocabulary_list' , 'rb') as f:\n",
    "     v_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75249e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_freq_list = []\n",
    "for v in vocab_list:\n",
    "    counter = 0\n",
    "    for p in preprocessed_data:\n",
    "        if v in p:\n",
    "            counter=counter+1\n",
    "    \n",
    "    doc_freq_list.append(counter)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f982be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(doc_freq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f40e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('Document_Frequency_List' , 'wb') as f:\n",
    "    pickle.dump(doc_freq_list , f)\n",
    "    \n",
    "with open('Document_Frequency_List' , 'rb') as f:\n",
    "     new_doc_freq_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdddf122",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = (len(file_names) ,len(new_doc_freq_list) )\n",
    "tf_idf_matrix = np.zeros(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4592f1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19112955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_doc_freq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "113a6f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5adfa7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = len(file_names)\n",
    "#i=0\n",
    "for i in range(len(v_list)):\n",
    "    idf = math.log10(total_docs/(new_doc_freq_list[i]+1))\n",
    "    #j=0\n",
    "    for j in range(len(file_names)):\n",
    "        tf_idf_matrix[j][i] = idf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d916f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix1 = tf_idf_matrix\n",
    "tf_idf_matrix2 = tf_idf_matrix\n",
    "tf_idf_matrix3 = tf_idf_matrix\n",
    "tf_idf_matrix4 = tf_idf_matrix\n",
    "tf_idf_matrix5 = tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b58a0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfid matrix with term weighing scheme (Binary)\n",
    "for i in range(len(v_list)):\n",
    "    word = v_list[i]\n",
    "    for j in range(len(file_names)):\n",
    "        if word not in preprocessed_data[j]:\n",
    "            tf_idf_matrix1[j][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb6b4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6283a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf_idf_mat1' , 'wb') as f:\n",
    "        pickle.dump(tf_idf_matrix1 , f)\n",
    "        \n",
    "with open('tf_idf_mat1' , 'rb') as f:\n",
    "     tf_idf_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bc59bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.75319991, 2.75319991, 1.90810187, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 2.75319991, 2.75319991,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        2.75319991]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0275dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method1(query_mod , tf_idf):\n",
    "    tfidf_net = []\n",
    "    for i in range(len(file_names)):\n",
    "        s = 0\n",
    "        for q in query_mod:\n",
    "            j = v_list.index(q)\n",
    "            s = s + tf_idf[i][j]\n",
    "        tfidf_net.append(s)\n",
    "    Z = [x for _,x in sorted(zip(tfidf_net,file_names))]\n",
    "    Z.reverse()\n",
    "    \n",
    "    return Z,tfidf_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a88a4a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a querydaily music television show with guests\n",
      "mlverb.hum\n",
      "manners.txt\n",
      "humor9.txt\n",
      "aboutada.txt\n",
      "sfmovie.txt\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter a query\")\n",
    "query_mod = preprocessing(query)\n",
    "Z,tfidf_net = method1(query_mod,tf_idf_1)\n",
    "for i in range(5):\n",
    "    print(Z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9f829177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daily', 'music', 'television', 'show', 'guests']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d96f1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfid matrix with term weighing scheme (Raw count)\n",
    "for i in range(len(v_list)):\n",
    "    word = v_list[i]\n",
    "    for j in range(len(file_names)):\n",
    "        if word not in preprocessed_data[j]:\n",
    "            tf_idf_matrix2[j][i] = 0\n",
    "        else:\n",
    "            tf_idf_matrix2[j][i] = tf_idf_matrix2[j][i] * preprocessed_data[j].count(word)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "944cd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf_idf_mat2' , 'wb') as f:\n",
    "        pickle.dump(tf_idf_matrix2 , f)\n",
    "        \n",
    "with open('tf_idf_mat2' , 'rb') as f:\n",
    "     tf_idf_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4eae4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.75319991, 2.75319991, 3.81620375, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 2.75319991, 2.75319991,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        5.50639983]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1643e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commword.hum\n",
      "rns_ency.txt\n",
      "stuf10.txt\n",
      "manners.txt\n",
      "sf-zine.pub\n"
     ]
    }
   ],
   "source": [
    "Z,tfidf_net = method1(query_mod,tf_idf_2)\n",
    "for i in range(5):\n",
    "    print(Z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "060b0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfid matrix with term weighing scheme (Term frequency)\n",
    "tf_idf_3 = tf_idf_2\n",
    "for i in range(len(file_names)):\n",
    "    doc_length = len(preprocessed_data[i])\n",
    "    for j in range(len(v_list)):\n",
    "        tf_idf_3[i][j] = tf_idf_3[i][j]/doc_length   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f11cc6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a querydaily music television show with guests\n",
      "popmusi.hum\n",
      "aboutada.txt\n",
      "commword.hum\n",
      "hbo_spec.rev\n",
      "rocking.hum\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter a query\")\n",
    "query_mod = preprocessing(query)\n",
    "Z,tfidf_net = method1(query_mod,tf_idf_3)\n",
    "for i in range(5):\n",
    "    print(Z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79a9df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfid matrix with term weighing scheme (Log Normalization)\n",
    "for i in range(len(v_list)):\n",
    "    word = v_list[i]\n",
    "    for j in range(len(file_names)):\n",
    "        if word not in preprocessed_data[j]:\n",
    "            tf_idf_matrix4[j][i] = 0\n",
    "        else:\n",
    "            tf_idf_matrix4[j][i] = tf_idf_matrix4[j][i] * math.log10(1+preprocessed_data[j].count(word))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f319f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf_idf_mat4' , 'wb') as f:\n",
    "        pickle.dump(tf_idf_matrix4 , f)\n",
    "        \n",
    "with open('tf_idf_mat4' , 'rb') as f:\n",
    "     tf_idf_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1112b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82879576, 0.82879576, 0.91039596, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.82879576, 0.82879576,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.3136102 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec83cab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a querydaily music television show with guests\n",
      "manners.txt\n",
      "humor9.txt\n",
      "mlverb.hum\n",
      "aboutada.txt\n",
      "stuf10.txt\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter a query\")\n",
    "query_mod = preprocessing(query)\n",
    "Z,tfidf_net = method1(query_mod,tf_idf_4)\n",
    "for i in range(5):\n",
    "    print(Z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4308adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfid matrix with term weighing scheme (Double Normalization)\n",
    "for i in range(len(v_list)):\n",
    "    word = v_list[i]\n",
    "    for j in range(len(file_names)):\n",
    "        if word not in preprocessed_data[j]:\n",
    "            tf_idf_matrix5[j][i] = tf_idf_matrix5[j][i] * 0.5\n",
    "        else:\n",
    "            most_freq_word = mode(preprocessed_data[j])\n",
    "            most_freq_count = preprocessed_data[j].count(most_freq_word)\n",
    "            tf_idf_matrix5[j][i] = tf_idf_matrix5[j][i] * (0.5 + 0.5*(preprocessed_data[j].count(word)/most_freq_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56ed8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf_idf_mat5' , 'wb') as f:\n",
    "        pickle.dump(tf_idf_matrix5 , f)\n",
    "with open('tf_idf_mat5' , 'rb') as f:\n",
    "     tf_idf_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c205106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48346419, 0.48346419, 0.60693064, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.49727745, 0.49727745,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.98520765]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0400b7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a querydaily music television show with guests\n",
      "commword.hum\n",
      "manners.txt\n",
      "popmusi.hum\n",
      "aboutada.txt\n",
      "humor9.txt\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter a query\")\n",
    "query_mod = preprocessing(query)\n",
    "Z,tfidf_net = method1(query_mod,tf_idf_5)\n",
    "for i in range(5):\n",
    "    print(Z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c89be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
