{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2ebf6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import math\n",
    "import statistics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from statistics import mode\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e13317",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/mohnish/20_newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c818e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'alt.atheism',\n",
       " 'class_list',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'feature_mat',\n",
       " 'misc.forsale',\n",
       " 'my_vocab_list',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc',\n",
       " 'tc_icf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa87b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "for filename in os.listdir():\n",
    "    if(filename=='comp.graphics' or filename=='sci.med' or filename=='talk.politics.misc'or filename=='rec.sport.hockey'or filename=='sci.space'):\n",
    "        file_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba83870d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'talk.politics.misc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430cfe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_for_file1=[]\n",
    "for (dirpath, dirnames, textfiles) in os.walk(str(os.getcwd())+\"/\"+\"comp.graphics\"):\n",
    "    for i in textfiles:\n",
    "        paths_for_file1.append(dirpath+\"/\"+i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2638eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_for_file2=[]\n",
    "for (dirpath, dirnames, textfiles) in os.walk(str(os.getcwd())+\"/\"+\"rec.sport.hockey\"):\n",
    "    for i in textfiles:\n",
    "        paths_for_file2.append(dirpath+\"/\"+i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b87d7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_for_file3=[]\n",
    "for (dirpath, dirnames, textfiles) in os.walk(str(os.getcwd())+\"/\"+\"sci.med\"):\n",
    "    for i in textfiles:\n",
    "        paths_for_file3.append(dirpath+\"/\"+i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46d67900",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_for_file4=[]\n",
    "for (dirpath, dirnames, textfiles) in os.walk(str(os.getcwd())+\"/\"+\"sci.space\"):\n",
    "    for i in textfiles:\n",
    "        paths_for_file4.append(dirpath+\"/\"+i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba98bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_for_file5=[]\n",
    "for (dirpath, dirnames, textfiles) in os.walk(str(os.getcwd())+\"/\"+\"talk.politics.misc\"):\n",
    "    for i in textfiles:\n",
    "        paths_for_file5.append(dirpath+\"/\"+i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8bf55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5730bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_num(data):\n",
    "    data = np.char.replace(data, \"0\", \" zero \")\n",
    "    data = np.char.replace(data, \"1\", \" one \")\n",
    "    data = np.char.replace(data, \"2\", \" two \")\n",
    "    data = np.char.replace(data, \"3\", \" three \")\n",
    "    data = np.char.replace(data, \"4\", \" four \")\n",
    "    data = np.char.replace(data, \"5\", \" five \")\n",
    "    data = np.char.replace(data, \"6\", \" six \")\n",
    "    data = np.char.replace(data, \"7\", \" seven \")\n",
    "    data = np.char.replace(data, \"8\", \" eight \")\n",
    "    data = np.char.replace(data, \"9\", \" nine \")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe59f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(d):\n",
    "    no_punc = []\n",
    "    d_lower=d.lower()\n",
    "    \n",
    "    nltk_tokens = nltk.word_tokenize(d_lower)\n",
    "    \n",
    "    nltk_tokens=remove_num(nltk_tokens)\n",
    "    \n",
    "    nltk_tokens = remove_punc(nltk_tokens)\n",
    "    \n",
    "    stop_words_removed = []\n",
    "    for w in nltk_tokens:\n",
    "        if w not in stop_words:\n",
    "            stop_words_removed.append(w)\n",
    "    \n",
    "    \n",
    "    new_words = []\n",
    "    for x in stop_words_removed:\n",
    "        if(x.isalnum() and x!=\" \"):\n",
    "            new_words.append(x)\n",
    "        \n",
    "        \n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "005af882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_paths(paths):\n",
    "    data=[]\n",
    "    for i in range(len(paths)):\n",
    "        try:\n",
    "            f = open(str(paths[i]) , encoding='utf8')\n",
    "            var=f.read().replace('\\n',\" \")\n",
    "            data.append(var)\n",
    "\n",
    "        except Exception as e:\n",
    "            f = open(str(paths[i]) , encoding='unicode_escape')\n",
    "            var=f.read().replace('\\n',\" \")\n",
    "            data.append(var)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7cb3f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_file1 = get_data_from_paths(paths_for_file1)\n",
    "data_from_file2 = get_data_from_paths(paths_for_file2)\n",
    "data_from_file3 = get_data_from_paths(paths_for_file3)\n",
    "data_from_file4 = get_data_from_paths(paths_for_file4)\n",
    "data_from_file5 = get_data_from_paths(paths_for_file5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5cff6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_from_file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7ea30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_file1_preprocessed = []\n",
    "data_from_file2_preprocessed = []\n",
    "data_from_file3_preprocessed = []\n",
    "data_from_file4_preprocessed = []\n",
    "data_from_file5_preprocessed = []\n",
    "for file_data in data_from_file1:\n",
    "    data_from_file1_preprocessed.append(preprocessing(file_data))\n",
    "for file_data in data_from_file2:\n",
    "    data_from_file2_preprocessed.append(preprocessing(file_data))   \n",
    "for file_data in data_from_file3:\n",
    "    data_from_file3_preprocessed.append(preprocessing(file_data))  \n",
    "for file_data in data_from_file4:\n",
    "    data_from_file4_preprocessed.append(preprocessing(file_data))   \n",
    "for file_data in data_from_file5:\n",
    "    data_from_file5_preprocessed.append(preprocessing(file_data))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f25cba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_data = data_from_file1_preprocessed+data_from_file2_preprocessed+data_from_file3_preprocessed+data_from_file4_preprocessed+data_from_file5_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69afcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary = []\n",
    "# for data in all_data:\n",
    "#     for word in data:\n",
    "#         if word not in vocabulary:\n",
    "#             vocabulary.append(word)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9faa8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('my_vocab_list' , 'wb') as f:\n",
    "#            pickle.dump(vocabulary , f)\n",
    "with open('my_vocab_list' , 'rb') as f:\n",
    "     v_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d05281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = (5 ,len(v_list) )\n",
    "tf_icf_matrix = np.zeros(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4903c8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 44033)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_icf_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5f264a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_freq_list=[]\n",
    "# for term in v_list:\n",
    "#     count = 0\n",
    "#     for file1 in data_from_file1_preprocessed:\n",
    "#         if term in file1:\n",
    "#             count=count+1\n",
    "#             break\n",
    "#     for file2 in data_from_file2_preprocessed:\n",
    "#         if term in file2:\n",
    "#             count=count+1\n",
    "#             break\n",
    "#     for file3 in data_from_file3_preprocessed:\n",
    "#         if term in file3:\n",
    "#             count=count+1\n",
    "#             break\n",
    "#     for file4 in data_from_file4_preprocessed:\n",
    "#         if term in file4:\n",
    "#             count=count+1\n",
    "#             break\n",
    "#     for file5 in data_from_file5_preprocessed:\n",
    "#         if term in file5:\n",
    "#             count=count+1\n",
    "#             break\n",
    "#     class_freq_list.append(count)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08a1b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('class_list' , 'wb') as f:\n",
    "#            pickle.dump(class_freq_list , f)\n",
    "with open('class_list' , 'rb') as f:\n",
    "     class_f_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5615ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only entered ICF values of each term\n",
    "for j in range(len(v_list)):\n",
    "    for i in range(5):\n",
    "        tf_icf_matrix[i][j] = math.log10(5/class_f_list[j])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c52d4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = (5 ,len(v_list) )\n",
    "tf_matrix = np.zeros(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3580dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(len(v_list)):\n",
    "#     count1 = 0\n",
    "#     for file1 in data_from_file1_preprocessed:\n",
    "#         count1 = count1 + file1.count(v_list[j])\n",
    "#     tf_matrix[0][j] = count1\n",
    "    \n",
    "#     count2=0\n",
    "#     for file2 in data_from_file2_preprocessed:\n",
    "#         count2 = count2 + file2.count(v_list[j])\n",
    "#     tf_matrix[1][j] = count2\n",
    "    \n",
    "#     count3=0\n",
    "#     for file3 in data_from_file3_preprocessed:\n",
    "#         count3 = count3 + file3.count(v_list[j])\n",
    "#     tf_matrix[2][j] = count3\n",
    "    \n",
    "#     count4=0\n",
    "#     for file4 in data_from_file4_preprocessed:\n",
    "#         count4 = count4 + file4.count(v_list[j])\n",
    "#     tf_matrix[3][j] = count4\n",
    "    \n",
    "#     count5=0\n",
    "#     for file5 in data_from_file5_preprocessed:\n",
    "#         count5 = count5 + file5.count(v_list[j])\n",
    "#     tf_matrix[4][j] = count5\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7952e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(len(v_list)):\n",
    "#     for i in range(5):\n",
    "#         tf_icf_matrix[i][j] = tf_icf_matrix[i][j]*tf_matrix[i][j]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a2018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e022e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tc_icf' , 'wb') as f:\n",
    "#            pickle.dump(tf_icf_matrix , f)\n",
    "with open('tc_icf' , 'rb') as f:\n",
    "     tc_icf_mat = pickle.load(f)\n",
    "#this is tc_icf matrix here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f64fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets take k = 5000\n",
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "116d1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_list1 = v_list\n",
    "tc_icf_scores_for_class1=[]\n",
    "for j in range(len(v_list)):\n",
    "    tc_icf_scores_for_class1.append(tc_icf_mat[0][j])\n",
    "    \n",
    "v_list2 = v_list\n",
    "tc_icf_scores_for_class2=[]\n",
    "for j in range(len(v_list)):\n",
    "    tc_icf_scores_for_class2.append(tc_icf_mat[1][j])\n",
    "    \n",
    "v_list3 = v_list\n",
    "tc_icf_scores_for_class3=[]\n",
    "for j in range(len(v_list)):\n",
    "    tc_icf_scores_for_class3.append(tc_icf_mat[2][j])  \n",
    "    \n",
    "v_list4 = v_list\n",
    "tc_icf_scores_for_class4=[]\n",
    "for j in range(len(v_list)):\n",
    "    tc_icf_scores_for_class4.append(tc_icf_mat[3][j])  \n",
    "    \n",
    "v_list5 = v_list\n",
    "tc_icf_scores_for_class5=[]\n",
    "for j in range(len(v_list)):\n",
    "    tc_icf_scores_for_class5.append(tc_icf_mat[4][j])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3dee41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting vocab list wrt tc_icf_score\n",
    "v_list1_new = [v_list1 for _,v_list1 in sorted(zip(tc_icf_scores_for_class1,v_list1))]\n",
    "v_list2_new = [v_list2 for _,v_list2 in sorted(zip(tc_icf_scores_for_class2,v_list2))]\n",
    "v_list3_new = [v_list3 for _,v_list3 in sorted(zip(tc_icf_scores_for_class3,v_list3))]\n",
    "v_list4_new = [v_list4 for _,v_list4 in sorted(zip(tc_icf_scores_for_class4,v_list4))]\n",
    "v_list5_new = [v_list5 for _,v_list5 in sorted(zip(tc_icf_scores_for_class5,v_list5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "911b5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_list1_new = v_list1_new[-k:]\n",
    "v_list2_new = v_list2_new[-k:]\n",
    "v_list3_new = v_list3_new[-k:]\n",
    "v_list4_new = v_list4_new[-k:]\n",
    "v_list5_new = v_list5_new[-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f45e52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vocab_list = list(set().union(v_list1_new, v_list2_new, v_list3_new , v_list4_new , v_list5_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24a89d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e66913c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = (5000 ,len(final_vocab_list))\n",
    "feature_matrix = np.zeros(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5734dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    for j in range(len(final_vocab_list)):\n",
    "        if final_vocab_list[j] in all_data[i]:\n",
    "            ind = v_list.index(final_vocab_list[j])\n",
    "            feature_matrix[i][j] = tc_icf_mat[0][ind]\n",
    "\n",
    "for i in range(1000,2000):\n",
    "    for j in range(len(final_vocab_list)):\n",
    "        if final_vocab_list[j] in all_data[i]:\n",
    "            ind = v_list.index(final_vocab_list[j])\n",
    "            feature_matrix[i][j] = tc_icf_mat[1][ind]\n",
    "            \n",
    "for i in range(2000,3000):\n",
    "    for j in range(len(final_vocab_list)):\n",
    "        if final_vocab_list[j] in all_data[i]:\n",
    "            ind = v_list.index(final_vocab_list[j])\n",
    "            feature_matrix[i][j] = tc_icf_mat[2][ind]\n",
    "            \n",
    "for i in range(3000,4000):\n",
    "    for j in range(len(final_vocab_list)):\n",
    "        if final_vocab_list[j] in all_data[i]:\n",
    "            ind = v_list.index(final_vocab_list[j])\n",
    "            feature_matrix[i][j] = tc_icf_mat[3][ind]\n",
    "            \n",
    "for i in range(4000,5000):\n",
    "    for j in range(len(final_vocab_list)):\n",
    "        if final_vocab_list[j] in all_data[i]:\n",
    "            ind = v_list.index(final_vocab_list[j])\n",
    "            feature_matrix[i][j] = tc_icf_mat[4][ind]\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3621dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature_mat' , 'wb') as f:\n",
    "           pickle.dump(feature_matrix , f)\n",
    "with open('feature_mat' , 'rb') as f:\n",
    "     feature_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79ec1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "for i in range(1000):\n",
    "    target.append(0)\n",
    "for i in range(1000,2000):\n",
    "    target.append(1)\n",
    "for i in range(2000,3000):\n",
    "    target.append(2)\n",
    "for i in range(3000,4000):\n",
    "    target.append(3)\n",
    "for i in range(4000,5000):\n",
    "    target.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1fba22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame(feature_matrix)\n",
    "df['Target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6ef16d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 49)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5c302759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "08770f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.437261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>116.596423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.095031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>116.596423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.095031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>116.596423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.095031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1    2    3    4    5    6    7           8    9  ...  \\\n",
       "0       0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  ...   \n",
       "1       0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  ...   \n",
       "2       0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  ...   \n",
       "3       0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  ...   \n",
       "4       0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  ...   \n",
       "...          ...  ...  ...  ...  ...  ...  ...  ...         ...  ...  ...   \n",
       "4995  116.596423  0.0  0.0  0.0  0.0  0.0  0.0  0.0  139.095031  0.0  ...   \n",
       "4996  116.596423  0.0  0.0  0.0  0.0  0.0  0.0  0.0  139.095031  0.0  ...   \n",
       "4997  116.596423  0.0  0.0  0.0  0.0  0.0  0.0  0.0  139.095031  0.0  ...   \n",
       "4998    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  ...   \n",
       "4999    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  ...   \n",
       "\n",
       "       40   41   42   43   44          45   46   47   48  Target  \n",
       "0     0.0  0.0  0.0  0.0  0.0    0.000000  0.0  0.0  0.0       0  \n",
       "1     0.0  0.0  0.0  0.0  0.0    0.000000  0.0  0.0  0.0       0  \n",
       "2     0.0  0.0  0.0  0.0  0.0    0.000000  0.0  0.0  0.0       0  \n",
       "3     0.0  0.0  0.0  0.0  0.0    0.000000  0.0  0.0  0.0       0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  110.437261  0.0  0.0  0.0       0  \n",
       "...   ...  ...  ...  ...  ...         ...  ...  ...  ...     ...  \n",
       "4995  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  0.0  0.0       4  \n",
       "4996  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  0.0  0.0       4  \n",
       "4997  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  0.0  0.0       4  \n",
       "4998  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  0.0  0.0       4  \n",
       "4999  0.0  0.0  0.0  0.0  0.0    0.000000  0.0  0.0  0.0       4  \n",
       "\n",
       "[5000 rows x 50 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3b249ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3f46f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# gnb = GaussianNB()\n",
    "# y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "# accuracy_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2b685067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBC():\n",
    "    \n",
    "    def prior_probability_calculation(self, features, target):\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy()\n",
    "        return self.prior\n",
    "    \n",
    "    def summary_calculation(self, features, target):\n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "        return self.mean, self.var\n",
    "    \n",
    "    def prob_density_distri(self, index_of_class, x):     \n",
    "        mean = self.mean[index_of_class]\n",
    "        var = self.var[index_of_class]\n",
    "        var=var+2\n",
    "        numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        prob = numerator / denominator\n",
    "        return prob\n",
    "    \n",
    "    def posterior_probability_calculation(self, x):\n",
    "        posteriors = []\n",
    "        for i in range(self.count):\n",
    "            prior = np.log(self.prior[i]) \n",
    "            conditional = np.sum(np.log(self.prob_density_distri(i, x)))\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "    \n",
    "    def fit(self, features, target):\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        self.summary_calculation(features, target)\n",
    "        self.prior_probability_calculation(features, target)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        preds = [self.posterior_probability_calculation(f) for f in features.to_numpy()]\n",
    "        return preds\n",
    "\n",
    "    def accuracy(self, y_test, y_pred):\n",
    "        accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "        return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dfe17631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df , ratio_test):\n",
    "    ratio_train = 1-ratio_test\n",
    "    shuffle_df = df.sample(frac=1)\n",
    "    train_size = int(ratio_train * len(df))\n",
    "    train_set = shuffle_df[:train_size]\n",
    "    test_set = shuffle_df[train_size:]\n",
    "    \n",
    "    x_test = test.drop(['Target'], axis = 1)\n",
    "    y_test = test['Target']\n",
    "    x_train = train.drop(['Target'], axis = 1)\n",
    "    y_train = train['Target']\n",
    "    \n",
    "    return x_train , y_train , x_test , y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b08e492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , y_train , x_test , y_test = train_test(df , 0.3)\n",
    "model = NBC()\n",
    "model.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b7b16180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohnish\\AppData\\Local\\Temp/ipykernel_12332/1626432690.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "  conditional = np.sum(np.log(self.prob_density_distri(i, x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[308,   0,   0,   0,   0],\n",
       "       [ 72, 235,   0,   0,   0],\n",
       "       [190,   0, 121,   0,   0],\n",
       "       [119,   0,   0, 154,   0],\n",
       "       [152,   0,  26,   0, 123]], dtype=int64)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0589bb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6273333333333333"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "93b4ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , y_train , x_test , y_test = train_test(df , 0.2)\n",
    "model = NBC()\n",
    "model.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6e88afc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohnish\\AppData\\Local\\Temp/ipykernel_12332/1626432690.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "  conditional = np.sum(np.log(self.prob_density_distri(i, x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[308,   0,   0,   0,   0],\n",
       "       [ 72, 235,   0,   0,   0],\n",
       "       [190,   0, 121,   0,   0],\n",
       "       [119,   0,   0, 154,   0],\n",
       "       [152,   0,  26,   0, 123]], dtype=int64)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4991086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6273333333333333"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4004fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , y_train , x_test , y_test = train_test(df , 0.5)\n",
    "model = NBC()\n",
    "model.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "8619dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohnish\\AppData\\Local\\Temp/ipykernel_12332/1626432690.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "  conditional = np.sum(np.log(self.prob_density_distri(i, x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[308,   0,   0,   0,   0],\n",
       "       [ 72, 235,   0,   0,   0],\n",
       "       [190,   0, 121,   0,   0],\n",
       "       [119,   0,   0, 154,   0],\n",
       "       [152,   0,  26,   0, 123]], dtype=int64)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ee4b7277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6273333333333333"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775fb27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
